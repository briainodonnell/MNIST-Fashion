{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - MNIST Fashion With Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Machine Learning UCD\n",
    "\n",
    "**Name:** Briain O'Donnell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import display, HTML, Image\n",
    "import io\n",
    "from operator import itemgetter\n",
    "\n",
    "from TAS_Python_Utilities import data_viz\n",
    "from TAS_Python_Utilities import data_viz_target\n",
    "from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a data sampling rate for speeding up testing\n",
    "data_sampling_rate = 0.1\n",
    "\n",
    "# Setup the number of folds for all grid searches\n",
    "cv_folds = 2\n",
    "\n",
    "# Set up a dictionary to store simple model performance comparions\n",
    "model_test_accuracy_comparisons = dict()\n",
    "model_valid_accuracy_comparisons = dict()\n",
    "model_tuned_params_list = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3:** Load and explore the MNIST fashion training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47838</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41675</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>123</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51857</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "47838      6       0       0       0       0       0       0       2      66   \n",
       "21303      0       0       0      78       0       0       0       1       0   \n",
       "41675      8       0       0       0       0       0       0       0       0   \n",
       "19985      2       0       0       0       0       1       0       0       0   \n",
       "51857      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "47838     124  ...        42        10         0         0         4   \n",
       "21303       0  ...         5        12         7        10         9   \n",
       "41675       0  ...         0         0         0         0         0   \n",
       "19985       0  ...         0         0         0       108       123   \n",
       "51857       0  ...         0         0        39        67        57   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "47838         0         0         0         0         0  \n",
       "21303         9        10         0         0         0  \n",
       "41675         0         0         0         0         0  \n",
       "19985        80         0         0         0         0  \n",
       "51857        49         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) # take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    624\n",
       "4    623\n",
       "6    605\n",
       "2    603\n",
       "1    601\n",
       "9    597\n",
       "3    596\n",
       "7    594\n",
       "8    584\n",
       "0    573\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the distribution of the classes\n",
    "dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "pixel5      0\n",
      "pixel6      0\n",
      "pixel7      0\n",
      "pixel8      0\n",
      "pixel9      0\n",
      "pixel10     0\n",
      "pixel11     0\n",
      "pixel12     0\n",
      "pixel13     0\n",
      "pixel14     0\n",
      "pixel15     0\n",
      "pixel16     0\n",
      "pixel17     0\n",
      "pixel18     0\n",
      "pixel19     0\n",
      "pixel20     0\n",
      "pixel21     0\n",
      "pixel22     0\n",
      "pixel23     0\n",
      "pixel24     0\n",
      "pixel25     0\n",
      "pixel26     0\n",
      "pixel27     0\n",
      "pixel28     0\n",
      "pixel29     0\n",
      "           ..\n",
      "pixel755    0\n",
      "pixel756    0\n",
      "pixel757    0\n",
      "pixel758    0\n",
      "pixel759    0\n",
      "pixel760    0\n",
      "pixel761    0\n",
      "pixel762    0\n",
      "pixel763    0\n",
      "pixel764    0\n",
      "pixel765    0\n",
      "pixel766    0\n",
      "pixel767    0\n",
      "pixel768    0\n",
      "pixel769    0\n",
      "pixel770    0\n",
      "pixel771    0\n",
      "pixel772    0\n",
      "pixel773    0\n",
      "pixel774    0\n",
      "pixel775    0\n",
      "pixel776    0\n",
      "pixel777    0\n",
      "pixel778    0\n",
      "pixel779    0\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Length: 785, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for presence of missing values\n",
    "print(\"Missing Values\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Isolating the descriptive features we are interested in\n",
    "X = dataset[dataset.columns[1:]]\n",
    "Y = np.array(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1158 ]  Sneaker\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1727 ]  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2739 ]  Sneaker\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1229 ]  Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4115 ]  Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 500 ]  Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4348 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 260 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2824 ]  Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a sample of images from the dataset\n",
    "for i in range(0, 9):\n",
    "    i_rand = randint(0, X.shape[0])\n",
    "\n",
    "    print(\"[\", i_rand, \"] \", classes[Y[i_rand]])\n",
    "    two_d = (X.iloc[i_rand].values.reshape(28, 28))\n",
    "    pyplot.imshow(two_d, cmap='gray')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data (this is important for some models)\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_filled</th>\n",
       "      <th>percent_filled_top</th>\n",
       "      <th>percent_filled_bottom</th>\n",
       "      <th>row_sum_0</th>\n",
       "      <th>row_sum_1</th>\n",
       "      <th>row_sum_2</th>\n",
       "      <th>row_sum_3</th>\n",
       "      <th>row_sum_4</th>\n",
       "      <th>row_sum_5</th>\n",
       "      <th>row_sum_6</th>\n",
       "      <th>...</th>\n",
       "      <th>row_sum_19</th>\n",
       "      <th>row_sum_20</th>\n",
       "      <th>row_sum_21</th>\n",
       "      <th>row_sum_22</th>\n",
       "      <th>row_sum_23</th>\n",
       "      <th>row_sum_24</th>\n",
       "      <th>row_sum_25</th>\n",
       "      <th>row_sum_26</th>\n",
       "      <th>row_sum_27</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47838</th>\n",
       "      <td>0.233944</td>\n",
       "      <td>0.243397</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.133613</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.233473</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.251541</td>\n",
       "      <td>0.248880</td>\n",
       "      <td>0.246499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233473</td>\n",
       "      <td>0.243417</td>\n",
       "      <td>0.248179</td>\n",
       "      <td>0.255602</td>\n",
       "      <td>0.263585</td>\n",
       "      <td>0.260364</td>\n",
       "      <td>0.245938</td>\n",
       "      <td>0.209804</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>0.210529</td>\n",
       "      <td>0.080512</td>\n",
       "      <td>0.340546</td>\n",
       "      <td>0.021989</td>\n",
       "      <td>0.057843</td>\n",
       "      <td>0.048039</td>\n",
       "      <td>0.035014</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366807</td>\n",
       "      <td>0.395518</td>\n",
       "      <td>0.422829</td>\n",
       "      <td>0.427031</td>\n",
       "      <td>0.444538</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.284034</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.028852</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41675</th>\n",
       "      <td>0.215931</td>\n",
       "      <td>0.141927</td>\n",
       "      <td>0.289936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082773</td>\n",
       "      <td>0.179692</td>\n",
       "      <td>0.047339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381513</td>\n",
       "      <td>0.356443</td>\n",
       "      <td>0.285994</td>\n",
       "      <td>0.725910</td>\n",
       "      <td>0.363585</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>0.398925</td>\n",
       "      <td>0.359634</td>\n",
       "      <td>0.438215</td>\n",
       "      <td>0.091597</td>\n",
       "      <td>0.147479</td>\n",
       "      <td>0.148459</td>\n",
       "      <td>0.315126</td>\n",
       "      <td>0.377591</td>\n",
       "      <td>0.396218</td>\n",
       "      <td>0.414706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.460924</td>\n",
       "      <td>0.461204</td>\n",
       "      <td>0.456162</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.462465</td>\n",
       "      <td>0.420448</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.221939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51857</th>\n",
       "      <td>0.276501</td>\n",
       "      <td>0.234574</td>\n",
       "      <td>0.318427</td>\n",
       "      <td>0.067927</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>0.186975</td>\n",
       "      <td>0.190196</td>\n",
       "      <td>0.213305</td>\n",
       "      <td>0.203501</td>\n",
       "      <td>0.220448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310504</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.433193</td>\n",
       "      <td>0.355742</td>\n",
       "      <td>0.316527</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.364006</td>\n",
       "      <td>0.314706</td>\n",
       "      <td>0.095658</td>\n",
       "      <td>0.058673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22353</th>\n",
       "      <td>0.154887</td>\n",
       "      <td>0.127351</td>\n",
       "      <td>0.182423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9769</th>\n",
       "      <td>0.255212</td>\n",
       "      <td>0.157303</td>\n",
       "      <td>0.353121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783613</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.520728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48201</th>\n",
       "      <td>0.438185</td>\n",
       "      <td>0.379342</td>\n",
       "      <td>0.497029</td>\n",
       "      <td>0.136134</td>\n",
       "      <td>0.184174</td>\n",
       "      <td>0.233053</td>\n",
       "      <td>0.331092</td>\n",
       "      <td>0.416106</td>\n",
       "      <td>0.389496</td>\n",
       "      <td>0.403782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529692</td>\n",
       "      <td>0.510084</td>\n",
       "      <td>0.505042</td>\n",
       "      <td>0.509664</td>\n",
       "      <td>0.505182</td>\n",
       "      <td>0.607283</td>\n",
       "      <td>0.646779</td>\n",
       "      <td>0.457563</td>\n",
       "      <td>0.064566</td>\n",
       "      <td>0.261480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49790</th>\n",
       "      <td>0.173299</td>\n",
       "      <td>0.202721</td>\n",
       "      <td>0.143878</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>0.161345</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.225630</td>\n",
       "      <td>0.233473</td>\n",
       "      <td>0.235714</td>\n",
       "      <td>0.241877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136835</td>\n",
       "      <td>0.144818</td>\n",
       "      <td>0.147619</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.164426</td>\n",
       "      <td>0.166387</td>\n",
       "      <td>0.161485</td>\n",
       "      <td>0.186695</td>\n",
       "      <td>0.129132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25340</th>\n",
       "      <td>0.506007</td>\n",
       "      <td>0.548980</td>\n",
       "      <td>0.463035</td>\n",
       "      <td>0.079272</td>\n",
       "      <td>0.432073</td>\n",
       "      <td>0.583754</td>\n",
       "      <td>0.591877</td>\n",
       "      <td>0.628431</td>\n",
       "      <td>0.631092</td>\n",
       "      <td>0.646078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489636</td>\n",
       "      <td>0.486134</td>\n",
       "      <td>0.539916</td>\n",
       "      <td>0.645098</td>\n",
       "      <td>0.461345</td>\n",
       "      <td>0.433473</td>\n",
       "      <td>0.385014</td>\n",
       "      <td>0.347059</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.211735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       percent_filled  percent_filled_top  percent_filled_bottom  row_sum_0  \\\n",
       "47838        0.233944            0.243397               0.224490   0.133613   \n",
       "21303        0.210529            0.080512               0.340546   0.021989   \n",
       "41675        0.215931            0.141927               0.289936   0.000000   \n",
       "19985        0.398925            0.359634               0.438215   0.091597   \n",
       "51857        0.276501            0.234574               0.318427   0.067927   \n",
       "22353        0.154887            0.127351               0.182423   0.000000   \n",
       "9769         0.255212            0.157303               0.353121   0.000000   \n",
       "48201        0.438185            0.379342               0.497029   0.136134   \n",
       "49790        0.173299            0.202721               0.143878   0.067227   \n",
       "25340        0.506007            0.548980               0.463035   0.079272   \n",
       "\n",
       "       row_sum_1  row_sum_2  row_sum_3  row_sum_4  row_sum_5  row_sum_6  ...  \\\n",
       "47838   0.336695   0.233473   0.254902   0.251541   0.248880   0.246499  ...   \n",
       "21303   0.057843   0.048039   0.035014   0.041036   0.041036   0.033613  ...   \n",
       "41675   0.000000   0.000000   0.000000   0.082773   0.179692   0.047339  ...   \n",
       "19985   0.147479   0.148459   0.315126   0.377591   0.396218   0.414706  ...   \n",
       "51857   0.178711   0.186975   0.190196   0.213305   0.203501   0.220448  ...   \n",
       "22353   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000  ...   \n",
       "9769    0.000000   0.000000   0.000000   0.000000   0.000000   0.039076  ...   \n",
       "48201   0.184174   0.233053   0.331092   0.416106   0.389496   0.403782  ...   \n",
       "49790   0.161345   0.201261   0.225630   0.233473   0.235714   0.241877  ...   \n",
       "25340   0.432073   0.583754   0.591877   0.628431   0.631092   0.646078  ...   \n",
       "\n",
       "       row_sum_19  row_sum_20  row_sum_21  row_sum_22  row_sum_23  row_sum_24  \\\n",
       "47838    0.233473    0.243417    0.248179    0.255602    0.263585    0.260364   \n",
       "21303    0.366807    0.395518    0.422829    0.427031    0.444538    0.435294   \n",
       "41675    0.381513    0.356443    0.285994    0.725910    0.363585    0.029692   \n",
       "19985    0.476190    0.460924    0.461204    0.456162    0.455882    0.447059   \n",
       "51857    0.310504    0.371429    0.433193    0.355742    0.316527    0.357143   \n",
       "22353    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "9769     0.783613    0.742717    0.520728    0.000000    0.000000    0.000000   \n",
       "48201    0.529692    0.510084    0.505042    0.509664    0.505182    0.607283   \n",
       "49790    0.136835    0.144818    0.147619    0.152941    0.164426    0.166387   \n",
       "25340    0.489636    0.486134    0.539916    0.645098    0.461345    0.433473   \n",
       "\n",
       "       row_sum_25  row_sum_26  row_sum_27  symmetry  \n",
       "47838    0.245938    0.209804    0.100700  0.008929  \n",
       "21303    0.284034    0.055462    0.028852  0.000000  \n",
       "41675    0.000000    0.000000    0.000000  0.029337  \n",
       "19985    0.462465    0.420448    0.085714  0.221939  \n",
       "51857    0.364006    0.314706    0.095658  0.058673  \n",
       "22353    0.000000    0.000000    0.000000  0.067602  \n",
       "9769     0.000000    0.000000    0.000000  0.070153  \n",
       "48201    0.646779    0.457563    0.064566  0.261480  \n",
       "49790    0.161485    0.186695    0.129132  0.000000  \n",
       "25340    0.385014    0.347059    0.188235  0.211735  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract some higher level features\n",
    "engineered_features = pd.DataFrame()\n",
    "\n",
    "# Calculate percentage of filled pixels and a top and bottom half only version\n",
    "percent_filled = X.sum(axis = 1)/(28*28)\n",
    "percent_filled_top = X.iloc[:, 0:392].sum(axis = 1)/(28*14)\n",
    "percent_filled_bottom = X.iloc[:, 392:784].sum(axis = 1)/(28*14)\n",
    "engineered_features['percent_filled'] = percent_filled\n",
    "engineered_features['percent_filled_top'] = percent_filled_top\n",
    "engineered_features['percent_filled_bottom'] = percent_filled_bottom\n",
    "\n",
    "# Calculate the sum of each row\n",
    "for idx, i in enumerate(range(0, 784, 28)):\n",
    "    row_sum = X.iloc[:, i:(i + 28)].sum(axis = 1)/28\n",
    "    engineered_features[\"row_sum_\" + str(idx)] = row_sum\n",
    "\n",
    "# Calcualte a measure of syymmetry around a horizontal axis\n",
    "s1 = np.round(np.array(X.iloc[:, 0:392]))\n",
    "s2 = np.round(np.array(X.iloc[:, 784:391:-1]))\n",
    "s3 = np.logical_and(s1, s2).astype(int)\n",
    "symmetry = s3.sum(axis = 1)/(28*28)\n",
    "\n",
    "engineered_features['symmetry'] = symmetry\n",
    "\n",
    "display(engineered_features.head(10))\n",
    "\n",
    "X = engineered_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4:** Split the data into a **training dataset**, a **validation dataset**, and a **test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test = train_test_split(X, Y, random_state=0, train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_plus_valid, y_train_plus_valid, random_state=0, train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Very Simple Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 5:** Train a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 6:** Assess the performance of the decision tree on the **training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       285\n",
      "           1       1.00      1.00      1.00       288\n",
      "           2       1.00      1.00      1.00       299\n",
      "           3       1.00      1.00      1.00       301\n",
      "           4       1.00      1.00      1.00       303\n",
      "           5       1.00      1.00      1.00       306\n",
      "           6       1.00      1.00      1.00       312\n",
      "           7       1.00      1.00      1.00       303\n",
      "           8       1.00      1.00      1.00       297\n",
      "           9       1.00      1.00      1.00       306\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>285</td>\n",
       "      <td>288</td>\n",
       "      <td>299</td>\n",
       "      <td>301</td>\n",
       "      <td>303</td>\n",
       "      <td>306</td>\n",
       "      <td>312</td>\n",
       "      <td>303</td>\n",
       "      <td>297</td>\n",
       "      <td>306</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          285    0    0    0    0    0    0    0    0    0   285\n",
       "1            0  288    0    0    0    0    0    0    0    0   288\n",
       "2            0    0  299    0    0    0    0    0    0    0   299\n",
       "3            0    0    0  301    0    0    0    0    0    0   301\n",
       "4            0    0    0    0  303    0    0    0    0    0   303\n",
       "5            0    0    0    0    0  306    0    0    0    0   306\n",
       "6            0    0    0    0    0    0  312    0    0    0   312\n",
       "7            0    0    0    0    0    0    0  303    0    0   303\n",
       "8            0    0    0    0    0    0    0    0  297    0   297\n",
       "9            0    0    0    0    0    0    0    0    0  306   306\n",
       "All        285  288  299  301  303  306  312  303  297  306  3000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the **validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5808333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.49      0.48       111\n",
      "           1       0.84      0.84      0.84       129\n",
      "           2       0.52      0.48      0.50       141\n",
      "           3       0.45      0.46      0.45       107\n",
      "           4       0.46      0.48      0.47       111\n",
      "           5       0.71      0.58      0.64       127\n",
      "           6       0.30      0.33      0.31       132\n",
      "           7       0.70      0.72      0.71       114\n",
      "           8       0.74      0.72      0.73       124\n",
      "           9       0.68      0.74      0.71       104\n",
      "\n",
      "    accuracy                           0.58      1200\n",
      "   macro avg       0.59      0.58      0.58      1200\n",
      "weighted avg       0.59      0.58      0.58      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>12</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>115</td>\n",
       "      <td>129</td>\n",
       "      <td>128</td>\n",
       "      <td>110</td>\n",
       "      <td>115</td>\n",
       "      <td>104</td>\n",
       "      <td>149</td>\n",
       "      <td>117</td>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           54    3    2   17    6    1   25    0    2    1   111\n",
       "1            4  108    2    9    1    0    5    0    0    0   129\n",
       "2           10    1   67    5   19    1   32    0    2    4   141\n",
       "3            8   12    5   49   10    3   18    0    1    1   107\n",
       "4            8    2   29    5   53    0   14    0    0    0   111\n",
       "5            1    0    0    4    1   74    1   25   14    7   127\n",
       "6           21    2   18   20   21    2   44    0    3    1   132\n",
       "7            1    0    0    0    0   18    1   82    2   10   114\n",
       "8            7    1    4    1    3    2    3    2   89   12   124\n",
       "9            1    0    1    0    1    3    6    8    7   77   104\n",
       "All        115  129  128  110  115  104  149  117  120  113  1200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) \n",
    "model_valid_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6011111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.51      0.52       177\n",
      "           1       0.82      0.82      0.82       184\n",
      "           2       0.43      0.45      0.44       163\n",
      "           3       0.47      0.49      0.48       188\n",
      "           4       0.49      0.41      0.44       209\n",
      "           5       0.74      0.65      0.69       191\n",
      "           6       0.27      0.35      0.30       161\n",
      "           7       0.79      0.78      0.79       177\n",
      "           8       0.80      0.77      0.78       163\n",
      "           9       0.78      0.78      0.78       187\n",
      "\n",
      "    accuracy                           0.60      1800\n",
      "   macro avg       0.61      0.60      0.60      1800\n",
      "weighted avg       0.61      0.60      0.61      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>13</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>146</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>176</td>\n",
       "      <td>183</td>\n",
       "      <td>169</td>\n",
       "      <td>197</td>\n",
       "      <td>175</td>\n",
       "      <td>169</td>\n",
       "      <td>214</td>\n",
       "      <td>174</td>\n",
       "      <td>157</td>\n",
       "      <td>186</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           91    7    6   29    6    2   32    0    4    0   177\n",
       "1            6  150    3   15    1    0    8    0    1    0   184\n",
       "2           11    0   73   11   37    0   31    0    0    0   163\n",
       "3           22   21    6   92   17    2   26    0    2    0   188\n",
       "4           11    2   47   12   85    1   48    0    2    1   209\n",
       "5            3    0    0    8    2  125    4   25    9   15   191\n",
       "6           25    3   27   25   19    1   57    0    3    1   161\n",
       "7            0    0    0    0    0   25    0  138    4   10   177\n",
       "8            4    0    5    1    5    3    3    4  125   13   163\n",
       "9            3    0    2    4    3   10    5    7    7  146   187\n",
       "All        176  183  169  197  175  169  214  174  157  186  1800"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "model_test_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less Overiftted Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree, setting min samples per leaf to a sensible value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split = 200)\n",
    "my_tree = my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6223333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.33      0.46       285\n",
      "           1       0.84      0.79      0.81       288\n",
      "           2       0.44      0.43      0.44       299\n",
      "           3       0.56      0.57      0.57       301\n",
      "           4       0.47      0.68      0.56       303\n",
      "           5       0.81      0.75      0.78       306\n",
      "           6       0.29      0.31      0.30       312\n",
      "           7       0.77      0.76      0.77       303\n",
      "           8       0.85      0.75      0.80       297\n",
      "           9       0.66      0.84      0.74       306\n",
      "\n",
      "    accuracy                           0.62      3000\n",
      "   macro avg       0.64      0.62      0.62      3000\n",
      "weighted avg       0.64      0.62      0.62      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>173</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>223</td>\n",
       "      <td>31</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>257</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>125</td>\n",
       "      <td>273</td>\n",
       "      <td>294</td>\n",
       "      <td>307</td>\n",
       "      <td>438</td>\n",
       "      <td>285</td>\n",
       "      <td>328</td>\n",
       "      <td>297</td>\n",
       "      <td>263</td>\n",
       "      <td>390</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           94    4   49   35   16    2   75    2    7    1   285\n",
       "1            4  228    0   33    0    0   23    0    0    0   288\n",
       "2            1    1  130    5  109    0   37    0    3   13   299\n",
       "3            8   32    7  173   18    0   56    1    4    2   301\n",
       "4            1    3   31   22  206    0   21    0    6   13   303\n",
       "5            0    0    1    7    0  230    9   40    3   16   306\n",
       "6           17    4   62   22   88    1   96    3   11    8   312\n",
       "7            0    0    0    0    0   24    0  230    0   49   303\n",
       "8            0    1    7    4    1    9    7   14  223   31   297\n",
       "9            0    0    7    6    0   19    4    7    6  257   306\n",
       "All        125  273  294  307  438  285  328  297  263  390  3000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5683333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.28      0.39       111\n",
      "           1       0.84      0.79      0.82       129\n",
      "           2       0.52      0.47      0.49       141\n",
      "           3       0.45      0.48      0.46       107\n",
      "           4       0.41      0.67      0.51       111\n",
      "           5       0.77      0.61      0.68       127\n",
      "           6       0.21      0.22      0.22       132\n",
      "           7       0.75      0.75      0.75       114\n",
      "           8       0.76      0.69      0.73       124\n",
      "           9       0.55      0.78      0.65       104\n",
      "\n",
      "    accuracy                           0.57      1200\n",
      "   macro avg       0.59      0.57      0.57      1200\n",
      "weighted avg       0.59      0.57      0.57      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>12</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>121</td>\n",
       "      <td>128</td>\n",
       "      <td>113</td>\n",
       "      <td>180</td>\n",
       "      <td>100</td>\n",
       "      <td>135</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>147</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                            \n",
       "0          31    2   18   16    7    0   31    0    3    3   111\n",
       "1           0  102    1   13    0    0   13    0    0    0   129\n",
       "2           1    1   66    5   42    0   21    0    3    2   141\n",
       "3           8   11    4   51    8    0   18    0    4    3   107\n",
       "4           0    2   10    7   74    0   11    0    1    6   111\n",
       "5           0    0    1    3    0   77    3   19    2   22   127\n",
       "6          10    3   19   15   45    4   29    0    6    1   132\n",
       "7           0    0    0    0    0   12    0   85    0   17   114\n",
       "8           0    0    5    2    2    3    8    6   86   12   124\n",
       "9           0    0    4    1    2    4    1    3    8   81   104\n",
       "All        50  121  128  113  180  100  135  113  113  147  1200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) \n",
    "model_valid_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5783333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.31      0.43       177\n",
      "           1       0.80      0.73      0.76       184\n",
      "           2       0.40      0.45      0.42       163\n",
      "           3       0.49      0.48      0.49       188\n",
      "           4       0.52      0.67      0.59       209\n",
      "           5       0.77      0.64      0.70       191\n",
      "           6       0.20      0.25      0.22       161\n",
      "           7       0.77      0.72      0.74       177\n",
      "           8       0.79      0.70      0.74       163\n",
      "           9       0.59      0.77      0.67       187\n",
      "\n",
      "    accuracy                           0.58      1800\n",
      "   macro avg       0.60      0.57      0.58      1800\n",
      "weighted avg       0.61      0.58      0.58      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>144</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>79</td>\n",
       "      <td>169</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>268</td>\n",
       "      <td>160</td>\n",
       "      <td>203</td>\n",
       "      <td>164</td>\n",
       "      <td>145</td>\n",
       "      <td>246</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                            \n",
       "0          55    3   39   25    7    1   42    0    5    0   177\n",
       "1           0  135    4   24    1    0   20    0    0    0   184\n",
       "2           1    1   73    5   56    0   23    0    2    2   163\n",
       "3           6   20   11   90   11    0   40    0    8    2   188\n",
       "4           4    3   19   11  140    0   22    0    1    9   209\n",
       "5           0    2    0    5    0  123    8   29    2   22   191\n",
       "6          13    5   28   16   48    0   40    0    4    7   161\n",
       "7           0    0    0    0    0   14    0  127    0   36   177\n",
       "8           0    0    6    2    4    7    3    3  114   24   163\n",
       "9           0    0    3    5    1   15    5    5    9  144   187\n",
       "All        79  169  183  183  268  160  203  164  145  246  1800"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "model_test_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Parameters Using a Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 7:** Use a grid search to tune the hyperparaemters for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63915094 0.59338061 0.64539007 0.61611374 0.62380952 0.64285714\n",
      " 0.61336516 0.65947242 0.63221154 0.60817308]\n"
     ]
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(max_depth = 12)\n",
    "scores = cross_val_score(my_tree, X_train_plus_valid, y_train_plus_valid, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try depths between 3 and 20 and different limits on the minimum number of samples per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.1s\n",
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5669047619047619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02598739, 0.03690124, 0.03789937, 0.0379138 , 0.036901  ,\n",
       "        0.03872383, 0.03790915, 0.03690028, 0.03774297, 0.03689861,\n",
       "        0.03692222, 0.03741956, 0.03739953, 0.03691411, 0.03790104,\n",
       "        0.03839719, 0.07430375, 0.10425162, 0.10721147, 0.10658407,\n",
       "        0.10333824, 0.10322368, 0.10754633, 0.10725665, 0.10723269,\n",
       "        0.10718977, 0.10922933, 0.10721803, 0.10773253, 0.10771143,\n",
       "        0.10771072, 0.10519683]),\n",
       " 'std_fit_time': array([1.33514404e-05, 2.38418579e-07, 2.74181366e-06, 9.98735428e-04,\n",
       "        9.98020172e-04, 8.36968422e-04, 9.95278358e-04, 9.98735428e-04,\n",
       "        1.97291374e-04, 1.04141235e-03, 1.01947784e-03, 5.17606735e-04,\n",
       "        4.97579575e-04, 1.00851059e-03, 9.91702080e-04, 1.49548054e-03,\n",
       "        5.02467155e-04, 2.47168541e-03, 1.45065784e-03, 8.70466232e-04,\n",
       "        5.78403473e-04, 1.49619579e-03, 2.15244293e-03, 1.45840645e-03,\n",
       "        1.51622295e-03, 1.47640705e-03, 4.76121902e-04, 1.50156021e-03,\n",
       "        1.97410583e-03, 9.54508781e-04, 1.98662281e-03, 5.19633293e-04]),\n",
       " 'mean_score_time': array([0.0015142 , 0.00097919, 0.00197446, 0.0014751 , 0.00199533,\n",
       "        0.00099814, 0.00148952, 0.00199401, 0.00197339, 0.00199521,\n",
       "        0.00199437, 0.00201738, 0.00199604, 0.00199032, 0.00150096,\n",
       "        0.00099719, 0.00149453, 0.0009892 , 0.00201774, 0.00100231,\n",
       "        0.00199795, 0.00199282, 0.00149977, 0.00147462, 0.00199592,\n",
       "        0.00149643, 0.00199533, 0.00199413, 0.00099707, 0.00149715,\n",
       "        0.0014962 , 0.001495  ]),\n",
       " 'std_score_time': array([5.18321991e-04, 2.05039978e-05, 1.80006027e-05, 4.77790833e-04,\n",
       "        4.76837158e-07, 8.34465027e-07, 5.03182411e-04, 1.54972076e-06,\n",
       "        2.38418579e-05, 5.96046448e-07, 1.66893005e-06, 1.91926956e-05,\n",
       "        2.38418579e-07, 1.43051147e-06, 5.04612923e-04, 1.07288361e-06,\n",
       "        4.96268272e-04, 5.00679016e-06, 1.97887421e-05, 4.05311584e-06,\n",
       "        2.86102295e-06, 2.02655792e-06, 5.03897667e-04, 5.20706177e-04,\n",
       "        8.34465027e-07, 4.98890877e-04, 4.76837158e-07, 2.86102295e-06,\n",
       "        9.53674316e-07, 4.98890877e-04, 4.98175621e-04, 4.97698784e-04]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42,\n",
       "                    45, 48, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36,\n",
       "                    39, 42, 45, 48],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 48, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 48, 'min_samples_split': 200}],\n",
       " 'split0_test_score': array([0.47716461, 0.56041865, 0.56850618, 0.56850618, 0.56850618,\n",
       "        0.56850618, 0.56850618, 0.56850618, 0.56850618, 0.56850618,\n",
       "        0.56850618, 0.56850618, 0.56850618, 0.56850618, 0.56850618,\n",
       "        0.56850618, 0.4885823 , 0.50666032, 0.50666032, 0.50666032,\n",
       "        0.50666032, 0.50666032, 0.50666032, 0.50666032, 0.50666032,\n",
       "        0.50666032, 0.50666032, 0.50666032, 0.50666032, 0.50666032,\n",
       "        0.50666032, 0.50666032]),\n",
       " 'split1_test_score': array([0.48236416, 0.56530029, 0.56530029, 0.56530029, 0.56530029,\n",
       "        0.56530029, 0.56530029, 0.56530029, 0.56530029, 0.56530029,\n",
       "        0.56530029, 0.56530029, 0.56530029, 0.56530029, 0.56530029,\n",
       "        0.56530029, 0.47187798, 0.54242135, 0.54242135, 0.54242135,\n",
       "        0.54242135, 0.54242135, 0.54242135, 0.54242135, 0.54242135,\n",
       "        0.54242135, 0.54242135, 0.54242135, 0.54242135, 0.54242135,\n",
       "        0.54242135, 0.54242135]),\n",
       " 'mean_test_score': array([0.4797619 , 0.56285714, 0.56690476, 0.56690476, 0.56690476,\n",
       "        0.56690476, 0.56690476, 0.56690476, 0.56690476, 0.56690476,\n",
       "        0.56690476, 0.56690476, 0.56690476, 0.56690476, 0.56690476,\n",
       "        0.56690476, 0.4802381 , 0.52452381, 0.52452381, 0.52452381,\n",
       "        0.52452381, 0.52452381, 0.52452381, 0.52452381, 0.52452381,\n",
       "        0.52452381, 0.52452381, 0.52452381, 0.52452381, 0.52452381,\n",
       "        0.52452381, 0.52452381]),\n",
       " 'std_test_score': array([0.00259977, 0.00244082, 0.00160295, 0.00160295, 0.00160295,\n",
       "        0.00160295, 0.00160295, 0.00160295, 0.00160295, 0.00160295,\n",
       "        0.00160295, 0.00160295, 0.00160295, 0.00160295, 0.00160295,\n",
       "        0.00160295, 0.00835216, 0.01788051, 0.01788051, 0.01788051,\n",
       "        0.01788051, 0.01788051, 0.01788051, 0.01788051, 0.01788051,\n",
       "        0.01788051, 0.01788051, 0.01788051, 0.01788051, 0.01788051,\n",
       "        0.01788051, 0.01788051]),\n",
       " 'rank_test_score': array([32, 15,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 31,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " 'split0_train_score': array([0.49380362, 0.61058151, 0.62249762, 0.62249762, 0.62249762,\n",
       "        0.62249762, 0.62249762, 0.62249762, 0.62249762, 0.62249762,\n",
       "        0.62249762, 0.62249762, 0.62249762, 0.62249762, 0.62249762,\n",
       "        0.62249762, 0.50905624, 0.56959009, 0.56959009, 0.56959009,\n",
       "        0.56959009, 0.56959009, 0.56959009, 0.56959009, 0.56959009,\n",
       "        0.56959009, 0.56959009, 0.56959009, 0.56959009, 0.56959009,\n",
       "        0.56959009, 0.56959009]),\n",
       " 'split1_train_score': array([0.49762131, 0.59609895, 0.59609895, 0.59609895, 0.59609895,\n",
       "        0.59609895, 0.59609895, 0.59609895, 0.59609895, 0.59609895,\n",
       "        0.59609895, 0.59609895, 0.59609895, 0.59609895, 0.59609895,\n",
       "        0.59609895, 0.49191246, 0.57469077, 0.57469077, 0.57469077,\n",
       "        0.57469077, 0.57469077, 0.57469077, 0.57469077, 0.57469077,\n",
       "        0.57469077, 0.57469077, 0.57469077, 0.57469077, 0.57469077,\n",
       "        0.57469077, 0.57469077]),\n",
       " 'mean_train_score': array([0.49571247, 0.60334023, 0.60929829, 0.60929829, 0.60929829,\n",
       "        0.60929829, 0.60929829, 0.60929829, 0.60929829, 0.60929829,\n",
       "        0.60929829, 0.60929829, 0.60929829, 0.60929829, 0.60929829,\n",
       "        0.60929829, 0.50048435, 0.57214043, 0.57214043, 0.57214043,\n",
       "        0.57214043, 0.57214043, 0.57214043, 0.57214043, 0.57214043,\n",
       "        0.57214043, 0.57214043, 0.57214043, 0.57214043, 0.57214043,\n",
       "        0.57214043, 0.57214043]),\n",
       " 'std_train_score': array([0.00190885, 0.00724128, 0.01319933, 0.01319933, 0.01319933,\n",
       "        0.01319933, 0.01319933, 0.01319933, 0.01319933, 0.01319933,\n",
       "        0.01319933, 0.01319933, 0.01319933, 0.01319933, 0.01319933,\n",
       "        0.01319933, 0.00857189, 0.00255034, 0.00255034, 0.00255034,\n",
       "        0.00255034, 0.00255034, 0.00255034, 0.00255034, 0.00255034,\n",
       "        0.00255034, 0.00255034, 0.00255034, 0.00255034, 0.00255034,\n",
       "        0.00255034, 0.00255034])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid ={'criterion': ['gini', \"entropy\"],\n",
    "             'max_depth': list(range(3, 50, 3)),\n",
    "             'min_samples_split': [200]}\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, cv=cv_folds, verbose = 2, return_train_score=True)\n",
    "my_tuned_tree.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)\n",
    "model_tuned_params_list[\"Tuned Tree\"] = my_tuned_tree.best_params_\n",
    "display(my_tuned_tree.best_score_)\n",
    "display(my_tuned_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5605555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.52      0.52       177\n",
      "           1       0.84      0.68      0.75       184\n",
      "           2       0.35      0.50      0.41       163\n",
      "           3       0.40      0.54      0.46       188\n",
      "           4       0.53      0.34      0.42       209\n",
      "           5       0.72      0.65      0.69       191\n",
      "           6       0.28      0.29      0.28       161\n",
      "           7       0.82      0.66      0.73       177\n",
      "           8       0.75      0.69      0.72       163\n",
      "           9       0.62      0.73      0.67       187\n",
      "\n",
      "    accuracy                           0.56      1800\n",
      "   macro avg       0.58      0.56      0.56      1800\n",
      "weighted avg       0.59      0.56      0.57      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>21</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>174</td>\n",
       "      <td>149</td>\n",
       "      <td>233</td>\n",
       "      <td>258</td>\n",
       "      <td>135</td>\n",
       "      <td>173</td>\n",
       "      <td>165</td>\n",
       "      <td>143</td>\n",
       "      <td>149</td>\n",
       "      <td>221</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           92    5   30   33    2    0    8    0    3    4   177\n",
       "1            3  125    7   45    0    0    3    0    0    1   184\n",
       "2           15    1   82    9   21    0   35    0    0    0   163\n",
       "3           13   15   29  102    5    0   10    0    1   13   188\n",
       "4           17    3   37   24   72    0   53    0    2    1   209\n",
       "5            0    0    1   11    0  125    1   18   11   24   191\n",
       "6           30    0   30   28   20    0   46    0    2    5   161\n",
       "7            0    0    0    0    0   31    0  117   13   16   177\n",
       "8            0    0    6    4    6    6    3    5  112   21   163\n",
       "9            4    0   11    2    9   11    6    3    5  136   187\n",
       "All        174  149  233  258  135  173  165  143  149  221  1800"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "model_test_accuracy_comparisons[\"Tuned Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 8:** We can easily use the same patterns to train other types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=200,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.RandomForestClassifier(n_estimators=300,  max_features = 3, min_samples_split=200)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.43      0.49       111\n",
      "           1       0.67      0.87      0.75       129\n",
      "           2       0.61      0.42      0.50       141\n",
      "           3       0.35      0.70      0.47       107\n",
      "           4       0.43      0.63      0.51       111\n",
      "           5       0.79      0.72      0.75       127\n",
      "           6       0.30      0.02      0.04       132\n",
      "           7       0.80      0.80      0.80       114\n",
      "           8       0.81      0.79      0.80       124\n",
      "           9       0.73      0.81      0.77       104\n",
      "\n",
      "    accuracy                           0.61      1200\n",
      "   macro avg       0.61      0.62      0.59      1200\n",
      "weighted avg       0.61      0.61      0.58      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>84</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>83</td>\n",
       "      <td>168</td>\n",
       "      <td>97</td>\n",
       "      <td>212</td>\n",
       "      <td>163</td>\n",
       "      <td>117</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>121</td>\n",
       "      <td>115</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1   2    3    4    5   6    7    8    9   All\n",
       "True                                                          \n",
       "0          48   19   8   29    2    0   2    0    3    0   111\n",
       "1           1  112   1   14    1    0   0    0    0    0   129\n",
       "2           3   15  59   26   33    0   1    0    4    0   141\n",
       "3           8   10   2   75    8    0   1    0    3    0   107\n",
       "4           2    2   8   26   70    0   3    0    0    0   111\n",
       "5           0    0   0    5    1   92   0   14    2   13   127\n",
       "6          20   10  14   33   41    5   3    0    6    0   132\n",
       "7           0    0   0    0    0   16   0   91    0    7   114\n",
       "8           1    0   4    3    1    2   0    4   98   11   124\n",
       "9           0    0   1    1    6    2   0    5    5   84   104\n",
       "All        83  168  97  212  163  117  10  114  121  115  1200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) \n",
    "model_valid_accuracy_comparisons[\"Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   0.9s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.0s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.2s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.1s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.1s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   1.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   1.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.8s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   1.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   1.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.6s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   1.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   1.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   2.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   2.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   2.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   2.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   1.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   1.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.8s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   2.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   2.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   2.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   2.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   2.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   2.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   3.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 6, 'min_samples_split': 200, 'n_estimators': 250}\n",
      "0.5959523809523809\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 501, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': [200] }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Random Forest\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6494444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.59      0.65       177\n",
      "           1       0.77      0.83      0.80       184\n",
      "           2       0.46      0.54      0.50       163\n",
      "           3       0.48      0.63      0.54       188\n",
      "           4       0.54      0.60      0.57       209\n",
      "           5       0.72      0.72      0.72       191\n",
      "           6       0.39      0.24      0.30       161\n",
      "           7       0.82      0.77      0.79       177\n",
      "           8       0.85      0.79      0.82       163\n",
      "           9       0.78      0.74      0.76       187\n",
      "\n",
      "    accuracy                           0.65      1800\n",
      "   macro avg       0.65      0.65      0.65      1800\n",
      "weighted avg       0.65      0.65      0.65      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>12</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>142</td>\n",
       "      <td>198</td>\n",
       "      <td>191</td>\n",
       "      <td>250</td>\n",
       "      <td>231</td>\n",
       "      <td>193</td>\n",
       "      <td>100</td>\n",
       "      <td>166</td>\n",
       "      <td>151</td>\n",
       "      <td>178</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          104   11   15   28    3    3    9    0    4    0   177\n",
       "1            1  152    2   25    0    0    4    0    0    0   184\n",
       "2            1    6   88   12   41    0   15    0    0    0   163\n",
       "3            9   24    9  119   10    0   11    0    6    0   188\n",
       "4            0    2   41   22  125    0   16    0    3    0   209\n",
       "5            0    1    1   10    0  138    0   23    2   16   191\n",
       "6           26    2   28   23   39    0   39    0    3    1   161\n",
       "7            0    0    0    0    0   30    0  136    1   10   177\n",
       "8            0    0    4    1    5    8    0    4  129   12   163\n",
       "9            1    0    3   10    8   14    6    3    3  139   187\n",
       "All        142  198  191  250  231  193  100  166  151  178  1800"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "model_test_accuracy_comparisons[\"Tuned Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='entropy',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=50,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=10, n_jobs=None,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 50), n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6208333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       111\n",
      "           1       0.82      0.87      0.84       129\n",
      "           2       0.58      0.50      0.54       141\n",
      "           3       0.46      0.54      0.50       107\n",
      "           4       0.45      0.67      0.54       111\n",
      "           5       0.73      0.71      0.72       127\n",
      "           6       0.28      0.17      0.21       132\n",
      "           7       0.75      0.77      0.76       114\n",
      "           8       0.84      0.69      0.76       124\n",
      "           9       0.68      0.83      0.74       104\n",
      "\n",
      "    accuracy                           0.62      1200\n",
      "   macro avg       0.62      0.63      0.62      1200\n",
      "weighted avg       0.62      0.62      0.61      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>15</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>95</td>\n",
       "      <td>137</td>\n",
       "      <td>123</td>\n",
       "      <td>127</td>\n",
       "      <td>165</td>\n",
       "      <td>123</td>\n",
       "      <td>83</td>\n",
       "      <td>118</td>\n",
       "      <td>102</td>\n",
       "      <td>127</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                           \n",
       "0          57    7    4   16    8    1  14    0    3    1   111\n",
       "1           2  112    2   10    0    0   3    0    0    0   129\n",
       "2           4    3   71   10   32    0  18    0    3    0   141\n",
       "3          12   12    3   58    6    5   7    0    2    2   107\n",
       "4           0    1   15   10   74    0  10    0    1    0   111\n",
       "5           0    0    1    2    0   90   1   19    2   12   127\n",
       "6          20    2   16   18   41    5  23    1    4    2   132\n",
       "7           0    0    0    0    0   16   0   88    1    9   114\n",
       "8           0    0    6    2    1    4   6    4   86   15   124\n",
       "9           0    0    5    1    3    2   1    6    0   86   104\n",
       "All        95  137  123  127  165  123  83  118  102  127  1200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) \n",
    "model_valid_accuracy_comparisons[\"Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50, total=   1.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50, total=   1.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100, total=   2.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100, total=   2.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150, total=   3.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150, total=   3.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200, total=   5.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200, total=   5.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250, total=   6.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250, total=   6.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300, total=   7.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300, total=   7.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350, total=   9.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350, total=   8.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400, total=  10.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400, total=  10.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450, total=  11.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450, total=  11.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500, total=  13.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500, total=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 350}\n",
      "0.4076190476190476\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    "  'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.BaggingClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Bagging\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5544444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.39      0.47       177\n",
      "           1       0.60      0.86      0.71       184\n",
      "           2       0.37      0.36      0.36       163\n",
      "           3       0.37      0.35      0.36       188\n",
      "           4       0.54      0.58      0.56       209\n",
      "           5       0.63      0.70      0.66       191\n",
      "           6       0.25      0.23      0.24       161\n",
      "           7       0.79      0.77      0.78       177\n",
      "           8       0.68      0.64      0.66       163\n",
      "           9       0.68      0.61      0.64       187\n",
      "\n",
      "    accuracy                           0.55      1800\n",
      "   macro avg       0.55      0.55      0.54      1800\n",
      "weighted avg       0.55      0.55      0.55      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>19</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>115</td>\n",
       "      <td>266</td>\n",
       "      <td>156</td>\n",
       "      <td>177</td>\n",
       "      <td>225</td>\n",
       "      <td>212</td>\n",
       "      <td>151</td>\n",
       "      <td>174</td>\n",
       "      <td>154</td>\n",
       "      <td>170</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           69   17   28   20    5    3   29    0    4    2   177\n",
       "1            4  159    1    9    0    1   10    0    0    0   184\n",
       "2            2   21   58   13   38    0   29    0    2    0   163\n",
       "3           20   40   11   65    6   11   26    0    5    4   188\n",
       "4            2   16   27   19  121    0   17    0    6    1   209\n",
       "5            0    0    0    9    0  133    1   28    3   17   191\n",
       "6           16   12   20   31   37    1   37    0    3    4   161\n",
       "7            0    0    0    0    0   24    0  137    8    8   177\n",
       "8            0    1    4    3    8   18    1    5  104   19   163\n",
       "9            2    0    7    8   10   21    1    4   19  115   187\n",
       "All        115  266  156  177  225  212  151  174  154  170  1800"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "model_test_accuracy_comparisons[\"Tuned Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='entropy',\n",
       "                                                         max_depth=None,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=200,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 200), n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4533333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.23      0.27       111\n",
      "           1       0.93      0.51      0.66       129\n",
      "           2       0.43      0.33      0.37       141\n",
      "           3       0.31      0.58      0.40       107\n",
      "           4       0.29      0.34      0.31       111\n",
      "           5       0.67      0.46      0.54       127\n",
      "           6       0.22      0.25      0.23       132\n",
      "           7       0.52      0.81      0.63       114\n",
      "           8       0.70      0.56      0.62       124\n",
      "           9       0.61      0.52      0.56       104\n",
      "\n",
      "    accuracy                           0.45      1200\n",
      "   macro avg       0.50      0.46      0.46      1200\n",
      "weighted avg       0.50      0.45      0.46      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>69</td>\n",
       "      <td>15</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>85</td>\n",
       "      <td>71</td>\n",
       "      <td>108</td>\n",
       "      <td>202</td>\n",
       "      <td>131</td>\n",
       "      <td>87</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>98</td>\n",
       "      <td>88</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1    2    3    4   5    6    7   8   9   All\n",
       "True                                                        \n",
       "0          26   2    7   45    8   0   21    0   1   1   111\n",
       "1           2  66    0   49    7   0    5    0   0   0   129\n",
       "2          12   0   46    9   40   0   30    0   1   3   141\n",
       "3           8   3    5   62    9   1   16    0   2   1   107\n",
       "4           5   0   23   10   38   0   35    0   0   0   111\n",
       "5           1   0    1    1    1  58    2   42  11  10   127\n",
       "6          21   0   20   24   23   5   33    0   5   1   132\n",
       "7           1   0    0    0    0  14    1   92   3   3   114\n",
       "8           7   0    6    2    5   2    0   18  69  15   124\n",
       "9           2   0    0    0    0   7    9   26   6  54   104\n",
       "All        85  71  108  202  131  87  152  178  98  88  1200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) \n",
    "model_valid_accuracy_comparisons[\"AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50, total=   3.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=50, total=   3.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100, total=   6.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=100, total=   6.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150, total=   8.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=150, total=   9.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200, total=  12.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=200, total=  11.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250, total=  14.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=250, total=  15.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300, total=  20.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=300, total=  21.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350, total=  15.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=350, total=  16.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400, total=  17.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=400, total=  18.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450, total=  19.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=450, total=  20.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500, total=  21.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), n_estimators=500, total=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=200, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 500}\n",
      "0.5852380952380952\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    " 'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.AdaBoostClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned AdaBoost\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.50      0.58       177\n",
      "           1       0.88      0.81      0.84       184\n",
      "           2       0.40      0.50      0.45       163\n",
      "           3       0.56      0.61      0.58       188\n",
      "           4       0.52      0.43      0.47       209\n",
      "           5       0.68      0.51      0.58       191\n",
      "           6       0.27      0.40      0.32       161\n",
      "           7       0.54      0.81      0.65       177\n",
      "           8       0.81      0.80      0.81       163\n",
      "           9       0.87      0.55      0.68       187\n",
      "\n",
      "    accuracy                           0.59      1800\n",
      "   macro avg       0.62      0.59      0.60      1800\n",
      "weighted avg       0.63      0.59      0.60      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>129</td>\n",
       "      <td>170</td>\n",
       "      <td>204</td>\n",
       "      <td>206</td>\n",
       "      <td>172</td>\n",
       "      <td>143</td>\n",
       "      <td>233</td>\n",
       "      <td>264</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           89    4   13   38    1    0   29    0    3    0   177\n",
       "1            6  149    2   18    1    0    8    0    0    0   184\n",
       "2            4    1   82    2   36    0   38    0    0    0   163\n",
       "3           14   15    4  115   13    0   24    0    3    0   188\n",
       "4            0    0   59    8   89    0   51    0    2    0   209\n",
       "5            1    0    0    6    1   97    1   71    3   11   191\n",
       "6           13    1   39   15   27    0   64    0    2    0   161\n",
       "7            0    0    0    0    0   29    0  143    4    1   177\n",
       "8            2    0    4    0    1    6    8    8  131    3   163\n",
       "9            0    0    1    4    3   11   10   42   13  103   187\n",
       "All        129  170  204  206  172  143  233  264  161  118  1800"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "model_test_accuracy_comparisons[\"Tuned AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with logistic regression\n",
    "my_model = linear_model.LogisticRegression()\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55       111\n",
      "           1       0.67      0.93      0.78       129\n",
      "           2       0.49      0.44      0.46       141\n",
      "           3       0.45      0.57      0.50       107\n",
      "           4       0.38      0.41      0.39       111\n",
      "           5       0.67      0.68      0.67       127\n",
      "           6       0.37      0.17      0.24       132\n",
      "           7       0.74      0.82      0.78       114\n",
      "           8       0.77      0.71      0.74       124\n",
      "           9       0.71      0.76      0.73       104\n",
      "\n",
      "    accuracy                           0.59      1200\n",
      "   macro avg       0.58      0.60      0.58      1200\n",
      "weighted avg       0.58      0.59      0.58      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>94</td>\n",
       "      <td>180</td>\n",
       "      <td>126</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>128</td>\n",
       "      <td>62</td>\n",
       "      <td>125</td>\n",
       "      <td>115</td>\n",
       "      <td>112</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                           \n",
       "0          56   23    2   18    2    4   5    0    1    0   111\n",
       "1           0  120    3    5    0    0   1    0    0    0   129\n",
       "2           6   14   62   11   32    4  10    0    2    0   141\n",
       "3          10    8   13   61    2    4   4    0    5    0   107\n",
       "4           0    5   27    9   46    2  11    0   11    0   111\n",
       "5           0    0    0    6    0   86   1   21    0   13   127\n",
       "6          21   10   11   15   35   10  23    0    5    2   132\n",
       "7           0    0    0    0    0   13   0   93    0    8   114\n",
       "8           1    0    3    9    4    4   2    3   88   10   124\n",
       "9           0    0    5    2    1    1   5    8    3   79   104\n",
       "All        94  180  126  136  122  128  62  125  115  112  1200"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) \n",
    "model_valid_accuracy_comparisons[\"Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1.8, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
      "0.6171428571428571\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'multi_class': ['ovr'], \n",
    " 'C': [x / 10.0 for x in range(2, 21, 2)],\n",
    " 'solver':['liblinear'],\n",
    "  'max_iter':[1000]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Logistic Regression\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6216666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.67       177\n",
      "           1       0.67      0.86      0.75       184\n",
      "           2       0.46      0.59      0.52       163\n",
      "           3       0.51      0.56      0.54       188\n",
      "           4       0.59      0.44      0.50       209\n",
      "           5       0.65      0.66      0.66       191\n",
      "           6       0.35      0.32      0.33       161\n",
      "           7       0.78      0.80      0.79       177\n",
      "           8       0.72      0.66      0.69       163\n",
      "           9       0.76      0.70      0.73       187\n",
      "\n",
      "    accuracy                           0.62      1800\n",
      "   macro avg       0.62      0.62      0.62      1800\n",
      "weighted avg       0.62      0.62      0.62      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>14</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>130</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>153</td>\n",
       "      <td>237</td>\n",
       "      <td>208</td>\n",
       "      <td>204</td>\n",
       "      <td>157</td>\n",
       "      <td>196</td>\n",
       "      <td>145</td>\n",
       "      <td>181</td>\n",
       "      <td>149</td>\n",
       "      <td>170</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          111   24   12   16    2    3    5    0    4    0   177\n",
       "1            3  158    4   18    0    0    1    0    0    0   184\n",
       "2            3   12   96    5   26    2   15    0    4    0   163\n",
       "3           15   22   12  105    1    6   20    0    7    0   188\n",
       "4            0    9   47   14   92    5   31    0   11    0   209\n",
       "5            0    0    2   11    0  127    2   31    3   15   191\n",
       "6           21   12   27   19   23    4   51    0    3    1   161\n",
       "7            0    0    0    0    0   24    0  142    1   10   177\n",
       "8            0    0    1    9   13   12    3    4  107   14   163\n",
       "9            0    0    7    7    0   13   17    4    9  130   187\n",
       "All        153  237  208  204  157  196  145  181  149  170  1800"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "model_test_accuracy_comparisons[\"Tuned Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neighbors.KNeighborsClassifier()\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6458333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55       111\n",
      "           1       0.71      0.95      0.81       129\n",
      "           2       0.53      0.49      0.51       141\n",
      "           3       0.54      0.63      0.58       107\n",
      "           4       0.46      0.54      0.50       111\n",
      "           5       0.80      0.65      0.71       127\n",
      "           6       0.51      0.33      0.40       132\n",
      "           7       0.77      0.82      0.79       114\n",
      "           8       0.90      0.74      0.81       124\n",
      "           9       0.71      0.82      0.76       104\n",
      "\n",
      "    accuracy                           0.65      1200\n",
      "   macro avg       0.65      0.65      0.64      1200\n",
      "weighted avg       0.65      0.65      0.64      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>114</td>\n",
       "      <td>172</td>\n",
       "      <td>129</td>\n",
       "      <td>124</td>\n",
       "      <td>131</td>\n",
       "      <td>103</td>\n",
       "      <td>84</td>\n",
       "      <td>121</td>\n",
       "      <td>102</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           62   21    6   12    2    1   6    0    1    0   111\n",
       "1            2  122    1    4    0    0   0    0    0    0   129\n",
       "2            5    8   69    6   37    1  11    0    1    3   141\n",
       "3           11   13    4   67    4    0   7    0    0    1   107\n",
       "4            1    2   26   10   60    0  11    0    0    1   111\n",
       "5            3    0    0    3    1   82   3   19    5   11   127\n",
       "6           27    6   18   15   20    1  43    0    2    0   132\n",
       "7            0    0    0    0    0   14   0   93    0    7   114\n",
       "8            3    0    3    5    4    3   0    2   92   12   124\n",
       "9            0    0    2    2    3    1   3    7    1   85   104\n",
       "All        114  172  129  124  131  103  84  121  102  120  1200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) \n",
    "model_valid_accuracy_comparisons[\"kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................................... n_neighbors=1, total=   0.2s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... n_neighbors=1, total=   0.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.2s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   0.2s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   0.2s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   0.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   0.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   0.2s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   0.2s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   0.2s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   0.2s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   0.2s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   0.2s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   0.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   0.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   0.2s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   0.3s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   0.2s\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 6}\n",
      "0.6530952380952381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned kNN\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6811111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71       177\n",
      "           1       0.72      0.91      0.80       184\n",
      "           2       0.46      0.62      0.53       163\n",
      "           3       0.56      0.64      0.60       188\n",
      "           4       0.64      0.54      0.59       209\n",
      "           5       0.77      0.66      0.71       191\n",
      "           6       0.42      0.37      0.39       161\n",
      "           7       0.82      0.83      0.82       177\n",
      "           8       0.92      0.77      0.84       163\n",
      "           9       0.81      0.80      0.81       187\n",
      "\n",
      "    accuracy                           0.68      1800\n",
      "   macro avg       0.69      0.68      0.68      1800\n",
      "weighted avg       0.69      0.68      0.68      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>152</td>\n",
       "      <td>232</td>\n",
       "      <td>220</td>\n",
       "      <td>214</td>\n",
       "      <td>177</td>\n",
       "      <td>166</td>\n",
       "      <td>139</td>\n",
       "      <td>180</td>\n",
       "      <td>137</td>\n",
       "      <td>183</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          117   21    9   19    1    0    8    0    2    0   177\n",
       "1            0  167    2   11    0    0    4    0    0    0   184\n",
       "2            2    8  101    6   23    0   22    0    1    0   163\n",
       "3           14   20   16  120    8    0    7    0    2    1   188\n",
       "4            0    3   46   18  113    0   27    0    1    1   209\n",
       "5            1    1    2   12    1  127    5   23    3   16   191\n",
       "6           18   12   34   15   22    0   59    0    1    0   161\n",
       "7            0    0    0    0    0   21    0  147    0    9   177\n",
       "8            0    0    7    3    5    9    3    3  126    7   163\n",
       "9            0    0    3   10    4    9    4    7    1  149   187\n",
       "All        152  232  220  214  177  166  139  180  137  183  1800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "model_test_accuracy_comparisons[\"Tuned kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neural_network.MLPClassifier(hidden_layer_sizes=(300, 100))\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65       111\n",
      "           1       0.83      0.90      0.87       129\n",
      "           2       0.59      0.63      0.61       141\n",
      "           3       0.71      0.61      0.66       107\n",
      "           4       0.51      0.55      0.53       111\n",
      "           5       0.83      0.72      0.77       127\n",
      "           6       0.48      0.42      0.45       132\n",
      "           7       0.80      0.78      0.79       114\n",
      "           8       0.89      0.81      0.85       124\n",
      "           9       0.70      0.92      0.80       104\n",
      "\n",
      "    accuracy                           0.70      1200\n",
      "   macro avg       0.70      0.70      0.70      1200\n",
      "weighted avg       0.70      0.70      0.70      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>112</td>\n",
       "      <td>139</td>\n",
       "      <td>151</td>\n",
       "      <td>91</td>\n",
       "      <td>119</td>\n",
       "      <td>111</td>\n",
       "      <td>117</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>137</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2   3    4    5    6    7    8    9   All\n",
       "True                                                            \n",
       "0           73    5    4  10    3    0   15    0    1    0   111\n",
       "1            1  116    3   4    0    0    5    0    0    0   129\n",
       "2            7    1   89   1   24    0   14    1    2    2   141\n",
       "3            7   13    6  65    3    1    9    0    1    2   107\n",
       "4            0    2   25   5   61    0   16    0    1    1   111\n",
       "5            1    0    0   2    0   92    0   15    4   13   127\n",
       "6           20    2   18   3   28    2   56    1    2    0   132\n",
       "7            0    0    0   0    0   12    0   89    1   12   114\n",
       "8            3    0    5   1    0    3    0    1  100   11   124\n",
       "9            0    0    1   0    0    1    2    4    0   96   104\n",
       "All        112  139  151  91  119  111  117  111  112  137  1200"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) \n",
    "model_valid_accuracy_comparisons[\"MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   5.3s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   5.3s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  13.7s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  13.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  16.7s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  17.0s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=   5.2s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=   5.3s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  13.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  14.1s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  16.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  16.7s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   5.2s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   5.4s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=  14.0s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=  13.8s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=  16.9s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=  16.5s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=   5.4s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=   5.4s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=  13.9s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=  13.9s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=  16.8s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=  17.0s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=   5.2s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=   5.4s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=  12.0s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=  13.8s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=  17.3s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=  17.1s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   5.2s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   5.3s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=  13.7s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=  13.7s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  14.6s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  16.7s\n",
      "Best parameters set found on development set:\n",
      "{'alpha': 1e-06, 'hidden_layer_sizes': (400, 200, 100)}\n",
      "0.7166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neural_network.MLPClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned MLP\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7288888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.61      0.68       177\n",
      "           1       0.91      0.89      0.90       184\n",
      "           2       0.50      0.66      0.57       163\n",
      "           3       0.70      0.72      0.71       188\n",
      "           4       0.65      0.66      0.65       209\n",
      "           5       0.82      0.76      0.79       191\n",
      "           6       0.47      0.42      0.44       161\n",
      "           7       0.85      0.85      0.85       177\n",
      "           8       0.85      0.82      0.83       163\n",
      "           9       0.81      0.86      0.83       187\n",
      "\n",
      "    accuracy                           0.73      1800\n",
      "   macro avg       0.73      0.73      0.73      1800\n",
      "weighted avg       0.74      0.73      0.73      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>161</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>140</td>\n",
       "      <td>181</td>\n",
       "      <td>215</td>\n",
       "      <td>194</td>\n",
       "      <td>213</td>\n",
       "      <td>178</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>156</td>\n",
       "      <td>199</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          108    2   18   14    2    0   30    0    3    0   177\n",
       "1            2  164    1   12    4    0    1    0    0    0   184\n",
       "2            1    2  108    4   33    0   13    0    1    1   163\n",
       "3           13    9    6  135    7    0   10    0    6    2   188\n",
       "4            0    1   38   12  138    1   17    0    1    1   209\n",
       "5            1    0    1    4    0  146    0   21    4   14   191\n",
       "6           15    3   35   10   26    0   68    0    3    1   161\n",
       "7            0    0    0    0    0   15    0  151    0   11   177\n",
       "8            0    0    6    0    3    6    4    3  133    8   163\n",
       "9            0    0    2    3    0   10    3    3    5  161   187\n",
       "All        140  181  215  194  213  178  146  178  156  199  1800"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "model_test_accuracy_comparisons[\"Tuned MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Simple Tree': 0.6011111111111112,\n",
       " 'Better Tree': 0.5783333333333334,\n",
       " 'Tuned Tree': 0.5605555555555556,\n",
       " 'Tuned Random Forest': 0.6494444444444445,\n",
       " 'Tuned Bagging': 0.5544444444444444,\n",
       " 'Tuned AdaBoost': 0.59,\n",
       " 'Tuned Logistic Regression': 0.6216666666666667,\n",
       " 'Tuned kNN': 0.6811111111111111,\n",
       " 'Tuned MLP': 0.7288888888888889}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_test_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.values()), align='center')\n",
    "_ = plt.yticks(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Simple Tree': 0.5808333333333333,\n",
       " 'Better Tree': 0.5683333333333334,\n",
       " 'Random Forest': 0.61,\n",
       " 'Bagging': 0.6208333333333333,\n",
       " 'AdaBoost': 0.4533333333333333,\n",
       " 'Logistic Regression': 0.595,\n",
       " 'kNN': 0.6458333333333334,\n",
       " 'MLP': 0.6975}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_valid_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Best Model On Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating the descriptive features we are interested in\n",
    "test_X = test_dataset[test_dataset.columns[1:]]\n",
    "test_Y = np.array(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data (this is important for some models)\n",
    "test_X = test_X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_filled</th>\n",
       "      <th>percent_filled_top</th>\n",
       "      <th>percent_filled_bottom</th>\n",
       "      <th>row_sum_0</th>\n",
       "      <th>row_sum_1</th>\n",
       "      <th>row_sum_2</th>\n",
       "      <th>row_sum_3</th>\n",
       "      <th>row_sum_4</th>\n",
       "      <th>row_sum_5</th>\n",
       "      <th>row_sum_6</th>\n",
       "      <th>...</th>\n",
       "      <th>row_sum_19</th>\n",
       "      <th>row_sum_20</th>\n",
       "      <th>row_sum_21</th>\n",
       "      <th>row_sum_22</th>\n",
       "      <th>row_sum_23</th>\n",
       "      <th>row_sum_24</th>\n",
       "      <th>row_sum_25</th>\n",
       "      <th>row_sum_26</th>\n",
       "      <th>row_sum_27</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399620</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>0.376851</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>0.078992</td>\n",
       "      <td>0.185994</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.550840</td>\n",
       "      <td>0.540196</td>\n",
       "      <td>0.518347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.391737</td>\n",
       "      <td>0.395098</td>\n",
       "      <td>0.395938</td>\n",
       "      <td>0.400560</td>\n",
       "      <td>0.393697</td>\n",
       "      <td>0.370728</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.212745</td>\n",
       "      <td>0.161990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210664</td>\n",
       "      <td>0.236134</td>\n",
       "      <td>0.185194</td>\n",
       "      <td>0.209664</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.291877</td>\n",
       "      <td>0.267787</td>\n",
       "      <td>0.248880</td>\n",
       "      <td>0.240756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199160</td>\n",
       "      <td>0.201821</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>0.202941</td>\n",
       "      <td>0.198039</td>\n",
       "      <td>0.191317</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>0.155742</td>\n",
       "      <td>0.084184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168382</td>\n",
       "      <td>0.193377</td>\n",
       "      <td>0.143387</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>0.267507</td>\n",
       "      <td>0.189076</td>\n",
       "      <td>0.192577</td>\n",
       "      <td>0.219328</td>\n",
       "      <td>0.205462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211345</td>\n",
       "      <td>0.240196</td>\n",
       "      <td>0.157423</td>\n",
       "      <td>0.139216</td>\n",
       "      <td>0.113165</td>\n",
       "      <td>0.079272</td>\n",
       "      <td>0.072129</td>\n",
       "      <td>0.028291</td>\n",
       "      <td>0.038375</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407893</td>\n",
       "      <td>0.460554</td>\n",
       "      <td>0.355232</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.455602</td>\n",
       "      <td>0.452101</td>\n",
       "      <td>0.430532</td>\n",
       "      <td>0.433053</td>\n",
       "      <td>0.462465</td>\n",
       "      <td>0.500560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374510</td>\n",
       "      <td>0.319888</td>\n",
       "      <td>0.264146</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>0.277311</td>\n",
       "      <td>0.257423</td>\n",
       "      <td>0.475070</td>\n",
       "      <td>0.725350</td>\n",
       "      <td>0.445798</td>\n",
       "      <td>0.103316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.252716</td>\n",
       "      <td>0.325090</td>\n",
       "      <td>0.180342</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.281092</td>\n",
       "      <td>0.360924</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>0.369328</td>\n",
       "      <td>0.381933</td>\n",
       "      <td>0.343277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251261</td>\n",
       "      <td>0.259664</td>\n",
       "      <td>0.216527</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.079082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.270638</td>\n",
       "      <td>0.251210</td>\n",
       "      <td>0.290066</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.181513</td>\n",
       "      <td>0.237255</td>\n",
       "      <td>0.223389</td>\n",
       "      <td>0.230952</td>\n",
       "      <td>0.228011</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271849</td>\n",
       "      <td>0.238515</td>\n",
       "      <td>0.256162</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.272829</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.298599</td>\n",
       "      <td>0.286975</td>\n",
       "      <td>0.188375</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.404432</td>\n",
       "      <td>0.368958</td>\n",
       "      <td>0.439906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780532</td>\n",
       "      <td>0.792997</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.123950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.290756</td>\n",
       "      <td>0.255282</td>\n",
       "      <td>0.326230</td>\n",
       "      <td>0.045238</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>0.185854</td>\n",
       "      <td>0.223389</td>\n",
       "      <td>0.243417</td>\n",
       "      <td>0.255462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346359</td>\n",
       "      <td>0.344398</td>\n",
       "      <td>0.332773</td>\n",
       "      <td>0.324790</td>\n",
       "      <td>0.347059</td>\n",
       "      <td>0.280532</td>\n",
       "      <td>0.261485</td>\n",
       "      <td>0.311204</td>\n",
       "      <td>0.283193</td>\n",
       "      <td>0.052296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.167462</td>\n",
       "      <td>0.139776</td>\n",
       "      <td>0.195148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>0.316947</td>\n",
       "      <td>0.357843</td>\n",
       "      <td>0.205042</td>\n",
       "      <td>0.085294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124790</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.178011</td>\n",
       "      <td>0.339916</td>\n",
       "      <td>0.399860</td>\n",
       "      <td>0.423249</td>\n",
       "      <td>0.176331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.215581</td>\n",
       "      <td>0.257233</td>\n",
       "      <td>0.173930</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>0.245238</td>\n",
       "      <td>0.248319</td>\n",
       "      <td>0.227731</td>\n",
       "      <td>0.203221</td>\n",
       "      <td>0.267227</td>\n",
       "      <td>0.389776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175350</td>\n",
       "      <td>0.173389</td>\n",
       "      <td>0.176611</td>\n",
       "      <td>0.185014</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.190616</td>\n",
       "      <td>0.192297</td>\n",
       "      <td>0.224090</td>\n",
       "      <td>0.107423</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   percent_filled  percent_filled_top  percent_filled_bottom  row_sum_0  \\\n",
       "0        0.399620            0.422389               0.376851   0.018347   \n",
       "1        0.210664            0.236134               0.185194   0.209664   \n",
       "2        0.168382            0.193377               0.143387   0.051961   \n",
       "3        0.407893            0.460554               0.355232   0.257143   \n",
       "4        0.252716            0.325090               0.180342   0.007563   \n",
       "5        0.270638            0.251210               0.290066   0.047479   \n",
       "6        0.404432            0.368958               0.439906   0.000000   \n",
       "7        0.290756            0.255282               0.326230   0.045238   \n",
       "8        0.167462            0.139776               0.195148   0.000000   \n",
       "9        0.215581            0.257233               0.173930   0.046218   \n",
       "\n",
       "   row_sum_1  row_sum_2  row_sum_3  row_sum_4  row_sum_5  row_sum_6  ...  \\\n",
       "0   0.078992   0.185994   0.414286   0.550840   0.540196   0.518347  ...   \n",
       "1   0.250000   0.267647   0.291877   0.267787   0.248880   0.240756  ...   \n",
       "2   0.157563   0.267507   0.189076   0.192577   0.219328   0.205462  ...   \n",
       "3   0.455602   0.452101   0.430532   0.433053   0.462465   0.500560  ...   \n",
       "4   0.281092   0.360924   0.362745   0.369328   0.381933   0.343277  ...   \n",
       "5   0.181513   0.237255   0.223389   0.230952   0.228011   0.247899  ...   \n",
       "6   0.000000   0.000000   0.000000   0.000000   0.000000   0.395098  ...   \n",
       "7   0.160784   0.236835   0.185854   0.223389   0.243417   0.255462  ...   \n",
       "8   0.030952   0.163165   0.316947   0.357843   0.205042   0.085294  ...   \n",
       "9   0.245238   0.248319   0.227731   0.203221   0.267227   0.389776  ...   \n",
       "\n",
       "   row_sum_19  row_sum_20  row_sum_21  row_sum_22  row_sum_23  row_sum_24  \\\n",
       "0    0.388235    0.391737    0.395098    0.395938    0.400560    0.393697   \n",
       "1    0.199160    0.201821    0.199860    0.202941    0.198039    0.191317   \n",
       "2    0.211345    0.240196    0.157423    0.139216    0.113165    0.079272   \n",
       "3    0.374510    0.319888    0.264146    0.236835    0.277311    0.257423   \n",
       "4    0.251261    0.259664    0.216527    0.034594    0.026751    0.017647   \n",
       "5    0.271849    0.238515    0.256162    0.267647    0.272829    0.282353   \n",
       "6    0.780532    0.792997    0.885714    0.123950    0.000000    0.000000   \n",
       "7    0.346359    0.344398    0.332773    0.324790    0.347059    0.280532   \n",
       "8    0.124790    0.178571    0.183333    0.178011    0.339916    0.399860   \n",
       "9    0.175350    0.173389    0.176611    0.185014    0.180952    0.190616   \n",
       "\n",
       "   row_sum_25  row_sum_26  row_sum_27  symmetry  \n",
       "0    0.370728    0.457843    0.212745  0.161990  \n",
       "1    0.185294    0.185294    0.155742  0.084184  \n",
       "2    0.072129    0.028291    0.038375  0.010204  \n",
       "3    0.475070    0.725350    0.445798  0.103316  \n",
       "4    0.016387    0.010364    0.010364  0.079082  \n",
       "5    0.298599    0.286975    0.188375  0.010204  \n",
       "6    0.000000    0.000000    0.000000  0.202806  \n",
       "7    0.261485    0.311204    0.283193  0.052296  \n",
       "8    0.423249    0.176331    0.000000  0.033163  \n",
       "9    0.192297    0.224090    0.107423  0.000000  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract some higher level features\n",
    "engineered_features_test = pd.DataFrame()\n",
    "\n",
    "# Calcualte percentage of filled pixels and a top and bottom half only version\n",
    "percent_filled = test_X.sum(axis = 1)/(28*28)\n",
    "percent_filled_top = test_X.iloc[:, 0:392].sum(axis = 1)/(28*14)\n",
    "percent_filled_bottom = test_X.iloc[:, 392:784].sum(axis = 1)/(28*14)\n",
    "engineered_features_test['percent_filled'] = percent_filled\n",
    "engineered_features_test['percent_filled_top'] = percent_filled_top\n",
    "engineered_features_test['percent_filled_bottom'] = percent_filled_bottom\n",
    "\n",
    "# Calculate the sum of each row\n",
    "for idx, i in enumerate(range(0, 784, 28)):\n",
    "    row_sum = test_X.iloc[:, i:(i + 28)].sum(axis = 1)/28\n",
    "    engineered_features_test[\"row_sum_\" + str(idx)] = row_sum\n",
    "\n",
    "# Calcualte a measure of syymmetry around a horizontal axis\n",
    "s1 = np.round(np.array(test_X.iloc[:, 0:392]))\n",
    "s2 = np.round(np.array(test_X.iloc[:, 784:391:-1]))\n",
    "s3 = np.logical_and(s1, s2).astype(int)\n",
    "symmetry = s3.sum(axis = 1)/(28*28)\n",
    "\n",
    "engineered_features_test['symmetry'] = symmetry\n",
    "\n",
    "display(engineered_features_test.head(10))\n",
    "\n",
    "test_X = engineered_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   7.5s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n",
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   6.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=  19.7s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=   6.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  23.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=  12.1s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=   7.4s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=   7.8s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=  19.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=   9.3s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  23.4s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=  13.6s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   7.6s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   7.6s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=  20.1s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=   8.9s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=  23.1s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=  10.0s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=   7.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=   6.8s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=  19.9s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=  17.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=  24.3s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=  23.3s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=   7.7s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=   7.7s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=  19.8s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=  11.0s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=  24.0s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=  14.3s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   7.5s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   7.6s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=  19.9s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=  15.9s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  24.1s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  8.4min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "my_model = my_tuned_model\n",
    "my_model = my_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71      1000\n",
      "           1       0.91      0.95      0.93      1000\n",
      "           2       0.56      0.76      0.64      1000\n",
      "           3       0.80      0.73      0.77      1000\n",
      "           4       0.68      0.67      0.67      1000\n",
      "           5       0.80      0.82      0.81      1000\n",
      "           6       0.59      0.42      0.49      1000\n",
      "           7       0.88      0.80      0.84      1000\n",
      "           8       0.88      0.85      0.86      1000\n",
      "           9       0.81      0.87      0.84      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>719</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>947</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>761</td>\n",
       "      <td>17</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>734</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>210</td>\n",
       "      <td>25</td>\n",
       "      <td>666</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>821</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>67</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>155</td>\n",
       "      <td>15</td>\n",
       "      <td>216</td>\n",
       "      <td>42</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>850</td>\n",
       "      <td>29</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>869</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1018</td>\n",
       "      <td>1046</td>\n",
       "      <td>1362</td>\n",
       "      <td>915</td>\n",
       "      <td>981</td>\n",
       "      <td>1029</td>\n",
       "      <td>707</td>\n",
       "      <td>909</td>\n",
       "      <td>966</td>\n",
       "      <td>1067</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1     2    3    4     5    6    7    8     9    All\n",
       "True                                                                   \n",
       "0           719    14    61   58   17     5  100    2   24     0   1000\n",
       "1             3   947    20   25    2     0    3    0    0     0   1000\n",
       "2            21     3   761   17  114     1   62    0   14     7   1000\n",
       "3            71    58    43  734   36     7   42    0    4     5   1000\n",
       "4            12     7   210   25  666     3   61    0   11     5   1000\n",
       "5            15     0     3   12    4   821    3   58   17    67   1000\n",
       "6           155    15   216   42  129     2  419    0   16     6   1000\n",
       "7             0     2     0    0    0   106    0  802   11    79   1000\n",
       "8            22     0    36    0    3    37   13   10  850    29   1000\n",
       "9             0     0    12    2   10    47    4   37   19   869   1000\n",
       "All        1018  1046  1362  915  981  1029  707  909  966  1067  10000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(test_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_Y, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(test_Y), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
